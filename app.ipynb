{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d545298c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instalando librer√≠as...\n",
      "‚úÖ Librer√≠as instaladas.\n"
     ]
    }
   ],
   "source": [
    "# --- Celda 1: Instalaciones ---\n",
    "# Instalamos Gradio (interfaz web), sentence-transformers (embeddings),\n",
    "# faiss-cpu (b√∫squeda vectorial) y la librer√≠a de Google (para Gemini).\n",
    "# --- Celda 1: Instalaciones ---\n",
    "print(\"Instalando librer√≠as...\")\n",
    "!pip install gradio sentence-transformers faiss-cpu google-generativeai python-dotenv --quiet\n",
    "print(\"‚úÖ Librer√≠as instaladas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c826c4e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Librer√≠as importadas.\n"
     ]
    }
   ],
   "source": [
    "# --- Celda 2: Importaciones ---\n",
    "import gradio as gr\n",
    "import json\n",
    "import numpy as np\n",
    "import faiss\n",
    "from pathlib import Path\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import google.generativeai as genai\n",
    "import os                       # üëà Importante para dotenv\n",
    "from dotenv import load_dotenv  # üëà Importamos la funci√≥n\n",
    "print(\"‚úÖ Librer√≠as importadas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a45ca2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ API Key de Gemini cargada de forma segura desde .env.\n"
     ]
    }
   ],
   "source": [
    "# --- Celda 3: Configuraci√≥n y API Key (con DotEnv) ---\n",
    "\n",
    "# 1. Cargar las variables del archivo .env a la memoria del sistema\n",
    "load_dotenv()\n",
    "\n",
    "# 2. Leer la API key desde las variables de entorno\n",
    "API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "if not API_KEY:\n",
    "    print(\"üõë ¬°ERROR! No se encontr√≥ 'GEMINI_API_KEY'.\")\n",
    "    print(\"Aseg√∫rate de haber creado el archivo .env y puesto la clave all√≠.\")\n",
    "else:\n",
    "    try:\n",
    "        genai.configure(api_key=API_KEY)\n",
    "        print(\"‚úÖ API Key de Gemini cargada de forma segura desde .env.\")\n",
    "    except Exception as e:\n",
    "        print(f\"üõë Error configurando la API Key: {e}\")\n",
    "\n",
    "# Nombres de archivos y modelos\n",
    "DATA_FILE = \"music_faiss_map_with_embeddings.json\"\n",
    "EMBED_MODEL = \"all-MiniLM-L6-v2\"\n",
    "GEMINI_MODEL = \"models/gemini-2.5-flash\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35274ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando datos desde music_faiss_map_with_embeddings.json...\n",
      "‚úÖ Canciones cargadas: 50\n",
      "Cargando modelo de embeddings 'all-MiniLM-L6-v2'...\n",
      "‚úÖ √çndice FAISS (el 'cerebro' de b√∫squeda) creado con 50 canciones.\n"
     ]
    }
   ],
   "source": [
    "# --- Celda 4: Cargar Datos y Construir el \"Cerebro\" (FAISS) ---\n",
    "\n",
    "p = Path(DATA_FILE)\n",
    "if not p.exists():\n",
    "    print(f\"‚ùå ERROR: No se encontr√≥ el archivo '{DATA_FILE}'.\")\n",
    "    print(\"Por favor, sube tu archivo JSON al panel de Archivos (a la izquierda).\")\n",
    "else:\n",
    "    print(f\"Cargando datos desde {DATA_FILE}...\")\n",
    "    data = json.loads(p.read_text(encoding=\"utf-8\"))\n",
    "    metas = data[\"metadatas\"]\n",
    "    print(f\"‚úÖ Canciones cargadas: {len(metas)}\")\n",
    "\n",
    "    # Cargar el modelo de embeddings\n",
    "    print(f\"Cargando modelo de embeddings '{EMBED_MODEL}'...\")\n",
    "    model = SentenceTransformer(EMBED_MODEL)\n",
    "\n",
    "    # Extraer embeddings y doc_ids para FAISS\n",
    "    embeddings = []\n",
    "    doc_ids = []\n",
    "    for doc_id, meta in metas.items():\n",
    "        emb = meta.get(\"embedding\")\n",
    "        if emb:\n",
    "            embeddings.append(np.array(emb, dtype=np.float32))\n",
    "            doc_ids.append(doc_id)\n",
    "\n",
    "    # Construir el √≠ndice FAISS\n",
    "    emb_matrix = np.vstack(embeddings)\n",
    "    faiss.normalize_L2(emb_matrix) # Normalizar para usar producto interno (IP)\n",
    "\n",
    "    dim = emb_matrix.shape[1]\n",
    "    index = faiss.IndexFlatIP(dim) # IP = Inner Product (producto escalar)\n",
    "    index.add(emb_matrix)\n",
    "\n",
    "    print(f\"‚úÖ √çndice FAISS (el 'cerebro' de b√∫squeda) creado con {index.ntotal} canciones.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1138281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Funciones RAG (embed, retrieve, build, call) definidas.\n"
     ]
    }
   ],
   "source": [
    "# --- Celda 5: Funciones del RAG (Las \"Herramientas\") ---\n",
    "\n",
    "def embed_query(query):\n",
    "    \"\"\"Convierte una consulta de texto en un vector embedding.\"\"\"\n",
    "    return model.encode([query], convert_to_numpy=True)[0]\n",
    "\n",
    "def retrieve_similar(query_emb, k=4):\n",
    "    \"\"\"Busca en FAISS los k documentos m√°s similares.\"\"\"\n",
    "    q = np.asarray(query_emb, dtype=np.float32).reshape(1, -1)\n",
    "    faiss.normalize_L2(q)\n",
    "    \n",
    "    D, I = index.search(q, k) # D=Distancias (scores), I=√çndices\n",
    "    \n",
    "    results = []\n",
    "    for score, idx in zip(D[0], I[0]):\n",
    "        song_id = doc_ids[idx]\n",
    "        meta = metas[song_id]\n",
    "        results.append({\n",
    "            \"doc_id\": song_id,\n",
    "            \"score\": float(score),\n",
    "            \"meta\": meta\n",
    "        })\n",
    "    return results\n",
    "\n",
    "def build_rag_prompt(query, retrieved_docs):\n",
    "    \"\"\"Construye el prompt para Gemini con el contexto encontrado.\"\"\"\n",
    "    context = \"\"\n",
    "    for i, doc in enumerate(retrieved_docs):\n",
    "        meta = doc[\"meta\"]\n",
    "        metadata_dict = meta.get('metadata', {})\n",
    "        context += f\"\"\"\n",
    "[Documento {i+1}]\n",
    "T√≠tulo: {meta.get('title', 'N/A')}\n",
    "Artista: {meta.get('artist', 'N/A')}\n",
    "A√±o: {metadata_dict.get('released', 'N/A')}\n",
    "G√©nero: {metadata_dict.get('genre', 'N/A')}\n",
    "\"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "Eres un asistente experto en m√∫sica llamado 'Discogs RAG'.\n",
    "Tu tarea es responder la pregunta del usuario bas√°ndote *√∫nicamente* en el contexto proporcionado.\n",
    "Si la respuesta no est√° en el contexto, di \"No encontr√© informaci√≥n sobre eso en mi base de datos\".\n",
    "\n",
    "---\n",
    "[CONTEXTO]\n",
    "{context.strip()}\n",
    "---\n",
    "\n",
    "[PREGUNTA DEL USUARIO]\n",
    "{query}\n",
    "\n",
    "[TU RESPUESTA]\n",
    "\"\"\"\n",
    "    return prompt\n",
    "\n",
    "def call_gemini(prompt_text):\n",
    "    \"\"\"Llama a la API de Gemini para generar una respuesta.\"\"\"\n",
    "    try:\n",
    "        model_obj = genai.GenerativeModel(GEMINI_MODEL)\n",
    "        response = model_obj.generate_content(prompt_text)\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        print(f\"Error al llamar a Gemini: {e}\")\n",
    "        return \"Hubo un error al contactar al modelo de IA. Por favor, revisa tu API Key.\"\n",
    "\n",
    "print(\"‚úÖ Funciones RAG (embed, retrieve, build, call) definidas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "050dca58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Funci√≥n 'orquestadora' de Gradio definida.\n"
     ]
    }
   ],
   "source": [
    "# --- Celda 6: Funci√≥n Principal (El \"Orquestador\") ---\n",
    "\n",
    "def responder_pregunta_rag(pregunta_usuario, historial_chat):\n",
    "    \"\"\"\n",
    "    Esta es la funci√≥n principal que Gradio llamar√°.\n",
    "    Recibe la pregunta y el historial, y devuelve la respuesta.\n",
    "    \"\"\"\n",
    "    if not pregunta_usuario.strip():\n",
    "        return \"Por favor, hazme una pregunta.\"\n",
    "\n",
    "    print(f\"\\nPregunta recibida: '{pregunta_usuario}'\")\n",
    "    \n",
    "    # Paso 1: Embed (Convertir pregunta a vector)\n",
    "    q_emb = embed_query(pregunta_usuario)\n",
    "    \n",
    "    # Paso 2: Retrieve (Buscar en FAISS)\n",
    "    retrieved_docs = retrieve_similar(q_emb, k=4)\n",
    "    \n",
    "    # Paso 3: Build Prompt (Construir prompt con contexto)\n",
    "    prompt = build_rag_prompt(pregunta_usuario, retrieved_docs)\n",
    "    print(f\"Prompt construido para Gemini:\\n{prompt}\\n\")\n",
    "    \n",
    "    # Paso 4: Generate (Llamar a Gemini)\n",
    "    respuesta = call_gemini(prompt)\n",
    "    \n",
    "    print(f\"Respuesta generada: '{respuesta}'\")\n",
    "    return respuesta\n",
    "\n",
    "print(\"‚úÖ Funci√≥n 'orquestadora' de Gradio definida.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34557c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Lanzando interfaz de Gradio...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bryan\\Desktop\\proyectosClase\\scraping\\Scraping171025\\.venv311\\Lib\\site-packages\\gradio\\chat_interface.py:347: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  self.chatbot = Chatbot(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "Could not create share link. Please check your internet connection or our status page: https://status.gradio.app.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pregunta recibida: 'tienes discos de rap'\n",
      "Prompt construido para Gemini:\n",
      "\n",
      "Eres un asistente experto en m√∫sica llamado 'Discogs RAG'.\n",
      "Tu tarea es responder la pregunta del usuario bas√°ndote *√∫nicamente* en el contexto proporcionado.\n",
      "Si la respuesta no est√° en el contexto, di \"No encontr√© informaci√≥n sobre eso en mi base de datos\".\n",
      "\n",
      "---\n",
      "[CONTEXTO]\n",
      "[Documento 1]\n",
      "T√≠tulo: LAX\n",
      "Artista: The Game (2)\n",
      "A√±o: 2008\n",
      "G√©nero: Hip Hop\n",
      "\n",
      "[Documento 2]\n",
      "T√≠tulo: Life 'N Perspectives Of A Genuine Crossover\n",
      "Artista: Urban Dance Squad\n",
      "A√±o: 2016-11-07\n",
      "G√©nero: Hip Hop, Rock\n",
      "\n",
      "[Documento 3]\n",
      "T√≠tulo: Kinematografia\n",
      "Artista: Paktofonika\n",
      "A√±o: N/A\n",
      "G√©nero: Hip Hop\n",
      "\n",
      "[Documento 4]\n",
      "T√≠tulo: Ascenseur Pour L'√©chafaud * Des Femmes Disparaissent\n",
      "Artista: The Miles Davis Quintet & Art Blakey & The Jazz Messengers\n",
      "A√±o: N/A\n",
      "G√©nero: Jazz, Stage & Screen\n",
      "---\n",
      "\n",
      "[PREGUNTA DEL USUARIO]\n",
      "tienes discos de rap\n",
      "\n",
      "[TU RESPUESTA]\n",
      "\n",
      "\n",
      "Respuesta generada: 'S√≠, tengo discos de rap:\n",
      "\n",
      "*   LAX de The Game (2)\n",
      "*   Life 'N Perspectives Of A Genuine Crossover de Urban Dance Squad\n",
      "*   Kinematografia de Paktofonika'\n",
      "\n",
      "Pregunta recibida: 'de que a√±o son'\n",
      "Prompt construido para Gemini:\n",
      "\n",
      "Eres un asistente experto en m√∫sica llamado 'Discogs RAG'.\n",
      "Tu tarea es responder la pregunta del usuario bas√°ndote *√∫nicamente* en el contexto proporcionado.\n",
      "Si la respuesta no est√° en el contexto, di \"No encontr√© informaci√≥n sobre eso en mi base de datos\".\n",
      "\n",
      "---\n",
      "[CONTEXTO]\n",
      "[Documento 1]\n",
      "T√≠tulo: Love, Strings & Jobim (The Eloquence Of Antonio Carlos Jobim)\n",
      "Artista: Antonio Carlos Jobim\n",
      "A√±o: 1966\n",
      "G√©nero: Jazz\n",
      "\n",
      "[Documento 2]\n",
      "T√≠tulo: Ascenseur Pour L'√©chafaud * Des Femmes Disparaissent\n",
      "Artista: The Miles Davis Quintet & Art Blakey & The Jazz Messengers\n",
      "A√±o: N/A\n",
      "G√©nero: Jazz, Stage & Screen\n",
      "\n",
      "[Documento 3]\n",
      "T√≠tulo: Scheisse Nicht Schon Wieder Bernstein\n",
      "Artista: Kommando Sonne-nmilch\n",
      "A√±o: 2008-10-10\n",
      "G√©nero: Rock\n",
      "\n",
      "[Documento 4]\n",
      "T√≠tulo: Kinematografia\n",
      "Artista: Paktofonika\n",
      "A√±o: N/A\n",
      "G√©nero: Hip Hop\n",
      "---\n",
      "\n",
      "[PREGUNTA DEL USUARIO]\n",
      "de que a√±o son\n",
      "\n",
      "[TU RESPUESTA]\n",
      "\n",
      "\n",
      "Respuesta generada: 'Aqu√≠ tienes la informaci√≥n sobre los a√±os de lanzamiento de los √°lbumes que encontr√© en mi base de datos:\n",
      "\n",
      "*   **Love, Strings & Jobim (The Eloquence Of Antonio Carlos Jobim)**: 1966\n",
      "*   **Ascenseur Pour L'√©chafaud * Des Femmes Disparaissent**: No se especifica el a√±o.\n",
      "*   **Scheisse Nicht Schon Wieder Bernstein**: 2008-10-10\n",
      "*   **Kinematografia**: No se especifica el a√±o.'\n"
     ]
    }
   ],
   "source": [
    "# --- Celda 7: ¬°Lanzar la Interfaz (Gradio)! ---\n",
    "\n",
    "print(\"üöÄ Lanzando interfaz de Gradio...\")\n",
    "\n",
    "iface = gr.ChatInterface(\n",
    "    fn=responder_pregunta_rag,\n",
    "    title=\"üéµ Experto Musical (RAG + Discogs)\",\n",
    "    description=\"Hazme una pregunta sobre la base de datos de m√∫sica. Usar√© RAG para encontrar la respuesta.\",\n",
    "    examples=[\n",
    "        \"¬øQu√© discos tiene jazz?\", \n",
    "        \"Recomi√©ndame vinilos de rock europeo\", \n",
    "        \"Canciones de rock cl√°sico con guitarras\"\n",
    "    ],\n",
    "    theme=\"soft\"\n",
    ")\n",
    "\n",
    "# .launch(share=True) crea un enlace p√∫blico temporal (72h)\n",
    "# para que puedas probarlo en tu navegador o tel√©fono.\n",
    "iface.launch(debug=True, share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
